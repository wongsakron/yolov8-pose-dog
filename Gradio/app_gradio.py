# app.py
import os, csv, time, shutil, subprocess
import uuid
import cv2
import numpy as np
import gradio as gr

from set_modal import (
    infer,            # ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á
    infer_frame_bgr,  # ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏ü‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    MIN_KP_CONF_DEFAULT
)

# ---------------- Utility ----------------
def _get_video_path(video):
    """‡∏î‡∏∂‡∏á path ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏≤‡∏Å‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï Gradio (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö)"""
    if video is None:
        return None
    if isinstance(video, str):
        return video if os.path.exists(video) else None
    if isinstance(video, dict):
        for k in ("path", "name", "tempfile", "file"):
            p = video.get(k)
            if isinstance(p, str) and os.path.exists(p):
                return p
    for attr in ("name", "path"):
        p = getattr(video, attr, None)
        if isinstance(p, str) and os.path.exists(p):
            return p
    return None

def _has_ffmpeg():
    return shutil.which("ffmpeg") is not None

def _ffmpeg_h264_writer(out_stub, fps, width, height):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå MP4 ‡∏î‡πâ‡∏ß‡∏¢ H.264 ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå"""
    fps = max(1.0, float(fps))
    out_mp4 = out_stub + ".mp4"
    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏Å‡∏ß‡πâ‡∏≤‡∏á/‡∏™‡∏π‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏π‡πà‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ yuv420p ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ
    vf = "scale=trunc(iw/2)*2:trunc(ih/2)*2,format=yuv420p"
    cmd = [
        "ffmpeg", "-y",
        "-f", "rawvideo", "-vcodec", "rawvideo",
        "-pix_fmt", "rgb24",
        "-s", f"{width}x{height}",
        "-r", f"{fps}",
        "-i", "-",
        "-an",
        "-vf", vf,
        "-c:v", "libx264",
        "-preset", "veryfast",
        "-movflags", "+faststart",
        "-pix_fmt", "yuv420p",
        out_mp4
    ]
    proc = subprocess.Popen(cmd, stdin=subprocess.PIPE)
    return proc, proc.stdin, out_mp4


# ---------------- App (UI ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏£‡∏Å + ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏°‡∏µ‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ----------------
with gr.Blocks(title="Dog Pose (Thai Labels) ‚Äì YOLO + Gradio") as app:
    gr.Markdown("## üê∂ Dog Pose Estimation (Thai Labels)\n‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏´‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ keypoints ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢")

    history = gr.State([])

    # ========== UI: ‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á ==========
    with gr.Tab("‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á"):
        with gr.Row():
            inp = gr.Image(type="pil", label="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û", container=True)
            out_img = gr.Image(type="numpy", label="‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå", interactive=False)

        with gr.Row():
            conf = gr.Slider(0.1, 0.95, value=0.5, step=0.05, label="‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (conf)")
            show_index = gr.Checkbox(value=False, label="‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏•‡∏Ç‡∏î‡∏±‡∏ä‡∏ô‡∏µ (0‚Äì25) ‡∏Ç‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î")

        run_btn = gr.Button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏†‡∏≤‡∏û‡∏ô‡∏¥‡πà‡∏á)")

        with gr.Row():
            with gr.Column(scale=1):
                pass
            with gr.Column(scale=2):
                with gr.Accordion("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢", open=False):
                    gallery = gr.Gallery(
                        label=None,
                        columns=3,
                        height=200,
                    )
            with gr.Column(scale=1):
                pass

        def predict_and_store(image, conf, show_index, hist):
            out_np, _ = infer(image, conf, show_index)
            if out_np is not None:
                hist = (hist or []) + [out_np]
                if len(hist) > 30:
                    hist = hist[-30:]
            return out_np, gr.update(value=hist), hist

        run_btn.click(
            fn=predict_and_store,
            inputs=[inp, conf, show_index, history],
            outputs=[out_img, gallery, history],
        )

        inp.upload(
            fn=predict_and_store,
            inputs=[inp, conf, show_index, history],
            outputs=[out_img, gallery, history],
        )

    # ========== UI: ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ==========
    with gr.Tab("‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠"):
        with gr.Row():
            in_vid = gr.Video(label="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠", sources=["upload"], interactive=True)
            out_vid = gr.Video(
                label="‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏•‡∏¥‡∏õ, MP4/H.264)",
                interactive=False,
                autoplay=True,
                show_download_button=True,
            )

        with gr.Row():
            conf_v = gr.Slider(0.1, 0.95, value=0.5, step=0.05, label="‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (conf)")
            show_index_v = gr.Checkbox(value=False, label="‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏•‡∏Ç‡∏î‡∏±‡∏ä‡∏ô‡∏µ (0‚Äì25) ‡∏Ç‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏∏‡∏î")
            frame_stride = gr.Slider(1, 8, value=1, step=1, label="‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏ü‡∏£‡∏° (frame_stride)")

        # ‚ùó ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏û‡∏µ‡∏¢‡∏á out_vid ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        def predict_video(video, conf, show_idx, stride, progress=gr.Progress()):
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ffmpeg ‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏Ñ‡∏∑‡∏ô‡πÑ‡∏ü‡∏•‡πå (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ gr.Video)
            if not _has_ffmpeg():
                return gr.update()

            vpath = _get_video_path(video)
            if not vpath or (not os.path.exists(vpath)):
                return gr.update()

            cap = cv2.VideoCapture(vpath)
            if not cap.isOpened():
                return gr.update()

            fps = cap.get(cv2.CAP_PROP_FPS) or 25.0
            W, H = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)

            base = os.path.splitext(os.path.basename(vpath))[0]
            uid = uuid.uuid4().hex[:8]
            out_stub = os.path.abspath(f"{base}_pred_{uid}")

            # ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô H.264 (stdin raw RGB -> ffmpeg)
            ff_proc, ff_stdin, out_path = _ffmpeg_h264_writer(
                out_stub, max(1.0, float(fps) / max(1, int(stride))), W, H
            )

            frame_idx = 0
            iterable = range(total) if total > 0 else range(10**9)
            for _ in progress.tqdm(iterable, desc="‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡∏™‡∏£‡πâ‡∏≤‡∏á MP4/H.264)"):
                ret, frame = cap.read()
                if not ret:
                    break

                if stride > 1 and (frame_idx % stride != 0):
                    frame_idx += 1
                    continue

                plotted_bgr, _rows = infer_frame_bgr(frame, conf, show_idx, MIN_KP_CONF_DEFAULT)

                # ‡∏™‡πà‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ ffmpeg ‡πÄ‡∏õ‡πá‡∏ô RGB24
                ff_stdin.write(cv2.cvtColor(plotted_bgr, cv2.COLOR_BGR2RGB).tobytes())

                frame_idx += 1
                if total == 0 and frame_idx > 2000:
                    break

            cap.release()
            try:
                ff_stdin.close()
            except Exception:
                pass
            ff_proc.wait()

            # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
            for _ in range(20):
                if os.path.exists(out_path) and os.path.getsize(out_path) > 0:
                    break
                time.sleep(0.1)

            # ‡∏Ñ‡∏∑‡∏ô "‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠" ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            return out_path

        run_video_btn = gr.Button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠")
        run_video_btn.click(
            fn=predict_video,
            inputs=[in_vid, conf_v, show_index_v, frame_stride],
            outputs=[out_vid],
            queue=True,
        )

app.queue().launch()
